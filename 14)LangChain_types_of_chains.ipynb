{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b43d3f-608e-4f75-8ba6-510d838b6d0d",
   "metadata": {},
   "source": [
    "| **Chain / Retriever**               | **Returns Citations** | **Method / Output Key**                          | **Status**             | **Docs Link**                                                                               |\n",
    "| ----------------------------------- | --------------------- | ------------------------------------------------ | ---------------------- | ------------------------------------------------------------------------------------------- |\n",
    "| `RetrievalQAWithSourcesChain`       | ‚úÖ Yes                 | `result['answer']`, `result['sources']`          | **Stable**             | [üîó Docs](https://docs.langchain.com/docs/modules/chains/popular/retrieval-qa-with-sources) |\n",
    "| `ConversationalRetrievalChain`      | ‚úÖ Yes                 | `result['answer']`, `result['source_documents']` | **Stable**             | [üîó Docs](https://docs.langchain.com/docs/modules/chains/popular/chat_vector_db)            |\n",
    "| `MultiRetrievalQAChain`             | ‚úÖ Yes                 | Depends on sub-chains used                       | **Stable**             | [üîó Docs](https://docs.langchain.com/docs/modules/chains/popular/multi_retrieval_qa)        |\n",
    "| `VectorDBQAWithSourcesChain`        | ‚úÖ Yes                 | `result['answer']`, `result['sources']`          | ‚úÖ (but legacy)         | [üîó Docs](https://docs.langchain.com/docs/modules/chains/popular/vector-db-qa)              |\n",
    "| `Tool` using RetrievalQAWithSources | ‚úÖ Yes                 | `result['answer']`, `result['sources']`          | **Stable** (via Agent) | [üîó Tools Docs](https://docs.langchain.com/docs/modules/agents/tools/custom_tools)          |\n",
    "| `RetrievalQA` (basic chain)         | ‚ùå No                  | Only `answer`                                    | **Stable**             | [üîó Docs](https://docs.langchain.com/docs/modules/chains/popular/retrieval-qa)              |\n",
    "| `RefineDocumentsChain`              | ‚ùå No                  | Only `answer`                                    | **Stable**             | [üîó Docs](https://docs.langchain.com/docs/modules/chains/document/refine)                   |\n",
    "| `StuffDocumentsChain`               | ‚ùå No                  | Only `answer`                                    | **Stable**             | [üîó Docs](https://docs.langchain.com/docs/modules/chains/document/stuff)                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70357767-bb85-4437-ab47-b7dc0a7639f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_26724\\4053161431.py:15: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_26724\\4053161431.py:16: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base setup complete.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Step 1: Imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# ‚úÖ Step 2: Load API key\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ‚úÖ Step 3: Setup LLM and Embeddings\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# ‚úÖ Step 4: Load and split document\n",
    "with open(\"sample.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=300, chunk_overlap=50)\n",
    "texts = splitter.split_text(raw_text)\n",
    "documents = [Document(page_content=t) for t in texts]\n",
    "\n",
    "# ‚úÖ Step 5: Vector Store (optional for Retriever chains)\n",
    "vectorstore = FAISS.from_texts(texts, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"‚úÖ Base setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0293d7-d339-48b4-913c-4b6bdd455115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14a6b75-a4bf-42aa-9c3c-32404a2681df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_26724\\3073877003.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_26724\\3073877003.py:17: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  stuff_chain = StuffDocumentsChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå StuffDocumentsChain Answer: The document is about LangChain, a framework created by Harrison Chase for building applications with LLMs. It discusses the features and uses of LangChain, such as supporting RAG, agents, memory, tools, chatbots, document Q&A, and AI workflow.\n"
     ]
    }
   ],
   "source": [
    "#‚úÖ 4. StuffDocumentsChain\n",
    "#Use case: Combines all docs into a single string before passing to LLM (best for small number of documents).\n",
    "\n",
    "from langchain.chains import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "# Define prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Use the following context to answer the question:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
    ")\n",
    "\n",
    "# Inner LLM Chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Stuff Chain\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"context\"\n",
    ")\n",
    "\n",
    "# Run\n",
    "response = stuff_chain.invoke({\n",
    "    \"input_documents\": documents[:3],  # test on 3 docs\n",
    "    \"question\": \"What is this document about?\"\n",
    "})\n",
    "\n",
    "print(\"\\nüìå StuffDocumentsChain Answer:\", response[\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d93fd-1860-4856-ad1e-0049c18e6851",
   "metadata": {},
   "source": [
    "# 5) Runnabale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0aab87-f9b7-484d-a553-21ad9adb3f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Refined Summary:\n",
      "\n",
      "LangChain is a framework developed by Harrison Chase for building applications with LLMs. It supports various features such as RAG, agents, memory, and tools, and is commonly used in chatbots, document Q&A, and AI workflow.\n"
     ]
    }
   ],
   "source": [
    "# Initial prompt to summarize the first chunk\n",
    "#Use case: Starts with a base answer and refines it using subsequent documents ‚Äî good when each chunk contributes incrementally.\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "initial_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Write a concise summary of the following text:\n",
    "\n",
    "{context}\n",
    "\"\"\")\n",
    "\n",
    "# Refine prompt to update the previous summary with new context\n",
    "refine_prompt = PromptTemplate.from_template(\"\"\"\n",
    "We have an existing summary:\n",
    "\"{existing_answer}\"\n",
    "\n",
    "Refine the summary with this new context:\n",
    "\"{context}\"\n",
    "\n",
    "If the context isn't useful, return the original summary.\n",
    "\"\"\")\n",
    "\n",
    "# Set up individual chains\n",
    "initial_summary_chain = initial_prompt | llm | StrOutputParser()\n",
    "refine_summary_chain = refine_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Start with first chunk\n",
    "summary = initial_summary_chain.invoke({\"context\": documents[0].page_content})\n",
    "\n",
    "# Iteratively refine with remaining docs\n",
    "for doc in documents[1:]:\n",
    "    summary = refine_summary_chain.invoke({\n",
    "        \"existing_answer\": summary,\n",
    "        \"context\": doc.page_content\n",
    "    })\n",
    "\n",
    "# Output final summary\n",
    "print(\"üìÑ Refined Summary:\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b4270-1b71-4f98-a24e-419056621652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
