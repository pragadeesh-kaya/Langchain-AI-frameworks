{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8cc5a1-2c9f-4256-8efc-a679003a3e9d",
   "metadata": {},
   "source": [
    "‚úÖ 4. ParentDocumentRetriever\n",
    "\n",
    "Use Case: Retrieve parent chunks based on a retrieval of smaller child chunks, great for keeping context intact in long documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c6925d-5650-4590-bd80-8a7998a3e675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_10804\\1140793398.py:21: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_10804\\1140793398.py:35: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(\"What are agents?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Retrieved Doc: Agents in LangChain use tools to answer questions.\n",
      "üìÑ Retrieved Doc: LangChain helps build LLM-powered apps with memory and agents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. Load environment\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 1. Prepare documents\n",
    "docs = [Document(page_content=\"LangChain helps build LLM-powered apps with memory and agents.\", metadata={\"id\": \"1\"}),\n",
    "        Document(page_content=\"Agents in LangChain use tools to answer questions.\", metadata={\"id\": \"2\"})]\n",
    "\n",
    "# 2. Setup child splitter\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "\n",
    "# 3. Setup vectorstore for children\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# 4. Parent retriever\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=InMemoryStore(),  # Stores parent docs\n",
    "    child_splitter=child_splitter\n",
    ")\n",
    "\n",
    "# 5. Add documents\n",
    "retriever.add_documents(docs)\n",
    "\n",
    "# 6. Retrieve\n",
    "results = retriever.get_relevant_documents(\"What are agents?\")\n",
    "for doc in results:\n",
    "    print(\"üìÑ Retrieved Doc:\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29717e69-5ffd-47bb-a879-e2af523bdc76",
   "metadata": {},
   "source": [
    "‚úÖ 5. BM25Retriever\n",
    "\n",
    "Use Case: Pure keyword-based search (like traditional search engines). No embeddings needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc280cc7-a974-48af-91ce-7e8c67aa41d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\envs\\langchainhope\\lib\\site-packages (from rank_bm25) (2.2.6)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481cbdfa-cdef-4587-a8e6-c0bff403eb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù BM25 Result: BM25 is a classical retrieval method.\n",
      "üìù BM25 Result: Vector search is powerful.\n",
      "üìù BM25 Result: LangChain enables LLM applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "# Create simple text docs\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain enables LLM applications.\"),\n",
    "    Document(page_content=\"Vector search is powerful.\"),\n",
    "    Document(page_content=\"BM25 is a classical retrieval method.\")\n",
    "]\n",
    "\n",
    "# Create BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "\n",
    "# Retrieve\n",
    "results = bm25_retriever.get_relevant_documents(\"How does BM25 work?\")\n",
    "for doc in results:\n",
    "    print(\"üìù BM25 Result:\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e436933-001a-4a63-a9fc-d6e8b45207b1",
   "metadata": {},
   "source": [
    "‚úÖ 6. EnsembleRetriever\n",
    "\n",
    "Use Case: Combine multiple retrievers (e.g., keyword + vector-based) with weighted scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a675d06a-2c9c-49d2-a279-9354dcda93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ensemble Doc: You can build AI apps using LangChain.\n",
      "üîç Ensemble Doc: LangChain supports LLMs.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "# Sample docs\n",
    "docs = [Document(page_content=\"LangChain supports LLMs.\"), Document(page_content=\"You can build AI apps using LangChain.\")]\n",
    "\n",
    "# BM25 Retriever\n",
    "bm25 = BM25Retriever.from_documents(docs)\n",
    "\n",
    "# Vector Retriever\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "vector_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Ensemble Retriever (equal weight)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25, vector_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Query\n",
    "results = ensemble_retriever.get_relevant_documents(\"AI apps using LangChain\")\n",
    "for doc in results:\n",
    "    print(\"üîç Ensemble Doc:\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac49892-52c3-496a-9d44-cab63ae1bd12",
   "metadata": {},
   "source": [
    "7.TimeWeightedVectorStoreRetriever\n",
    "\n",
    "#This retriever boosts document relevance by factoring recency and importance of interactions (used in agents with memory or relevance ranking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c962678-359b-4304-8c14-bac43c1b5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_17420\\1472465846.py:34: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(\"LangChain\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Documents:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings   # <-- FIXED IMPORT\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Initialize embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain is for LLM-based apps\", metadata={\"last_accessed_at\": datetime.now()}),\n",
    "    Document(page_content=\"Vector search improves relevance\", metadata={\"last_accessed_at\": datetime.now()}),\n",
    "]\n",
    "\n",
    "# Create vectorstore\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# Create retriever\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    decay_rate=0.01,\n",
    "    k=5,\n",
    "    search_kwargs={\"k\": 5}   # <-- ensures results return\n",
    ")\n",
    "\n",
    "# Retrieve\n",
    "results = retriever.get_relevant_documents(\"LangChain\")\n",
    "\n",
    "print(\"\\nRetrieved Documents:\\n\")\n",
    "for r in results:\n",
    "    print(\"---- Document ----\")\n",
    "    print(\"Content:\", r.page_content)\n",
    "    print(\"Metadata:\", r.metadata)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f39edcb-ff4b-4956-ac0f-57b82f724e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5aa949-c24f-4ced-aa97-e0737c41ba28",
   "metadata": {},
   "source": [
    "8.TavilySearchAPIRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c81784a-e7c5-4efb-bc43-aa79043903f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... LangChain 1.1. LangChain v1.1.0 is now available This release makes agent development more reliable, more structured, and more context-aware ‚Äî powered by a new\n",
      "The langchain namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to langchain-classic . To upgrade\n",
      "LangChain provides the engineering platform and open source frameworks developers use to build, test, and deploy reliable AI agents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import TavilySearchAPIRetriever\n",
    "import os\n",
    "\n",
    "# Set your Tavily API key\n",
    "#os.environ[\"TAVILY_API_KEY\"] = \"your_tavily_api_key\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# üîê Load API keys\n",
    "load_dotenv(\".env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Initialize Tavily Retriever\n",
    "retriever = TavilySearchAPIRetriever(k=3)\n",
    "\n",
    "# Perform search\n",
    "docs = retriever.get_relevant_documents(\"Latest updates about LangChain\")\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4957e8-0b32-443a-b64c-27bb3485be7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8950db-a066-4f2e-afa3-7d8a463e8ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab5590-36df-443a-a815-8913f55490b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
