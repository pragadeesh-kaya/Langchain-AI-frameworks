{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fcbb4ad-b3b6-413f-a139-83651544e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_34264\\680761851.py:13: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_34264\\680761851.py:17: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Simple QA Tool Output:\n",
      " LangGraph in LangChain is a graph database that stores and manages language data in a structured format, allowing for efficient retrieval and analysis of linguistic information.\n",
      "\n",
      "üìù Summarizer Tool Output:\n",
      " LangGraph is a library that allows developers to create stateful, multi-step agents as graphs using LangChain. Each node in the graph represents a step, such as calling an LLM or a tool, making it ideal for advanced AI workflows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import Tool\n",
    "\n",
    "# üîê Load API keys\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# üî∏ Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# ‚úÖ Tool 1: Simple QA Tool\n",
    "qa_prompt = PromptTemplate.from_template(\"Answer clearly: {question}\")\n",
    "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
    "qa_tool = Tool(\n",
    "    name=\"Simple QA\",\n",
    "    func=qa_chain.run,\n",
    "    description=\"Answer factual questions clearly\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Tool 2: Summarizer Tool\n",
    "summary_prompt = PromptTemplate.from_template(\"Summarize the following text:\\n\\n{text}\")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "summary_tool = Tool(\n",
    "    name=\"Summarizer\",\n",
    "    func=summary_chain.run,\n",
    "    description=\"Summarizes input text\"\n",
    ")\n",
    "\n",
    "# üîß Tool usage examples\n",
    "qa_query = \"What is LangGraph in LangChain?\"\n",
    "summary_text = \"\"\"\n",
    "LangGraph is a library built on top of LangChain that helps developers create stateful, multi-step agents \n",
    "as graphs. Each node represents a step like calling an LLM or a tool. It's ideal for advanced AI workflows.\n",
    "\"\"\"\n",
    "\n",
    "# üöÄ Run tools manually\n",
    "print(\"\\nüß† Simple QA Tool Output:\\n\", qa_tool.run({\"question\": qa_query}))\n",
    "print(\"\\nüìù Summarizer Tool Output:\\n\", summary_tool.run({\"text\": summary_text}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bb85c-d785-4306-b109-261362761d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
