{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267a9372-4436-4b1b-8064-c685266efed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_18812\\855904649.py:20: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0)\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_18812\\855904649.py:31: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_18812\\855904649.py:46: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_18812\\855904649.py:49: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n",
      "C:\\Users\\Pragadeesh K\\AppData\\Local\\Temp\\ipykernel_18812\\855904649.py:60: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res1 = agent.run(\"What is LangChain?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Ô∏è‚É£ First Question\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: LangChainRetriever\n",
      "Action Input: What is LangChain?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain is a framework created by Harrison Chase for building applications with Large Language Models (LLMs). It supports various features such as RAG, agents, memory, tools, and more. LangChain is commonly used in applications like chatbots, document Q&A, and AI workflow.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: LangChain is a framework created by Harrison Chase for building applications with Large Language Models (LLMs). It supports various features such as RAG, agents, memory, tools, and more. LangChain is commonly used in applications like chatbots, document Q&A, and AI workflow.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: LangChain is a framework created by Harrison Chase for building applications with Large Language Models (LLMs). It supports various features such as RAG, agents, memory, tools, and more. LangChain is commonly used in applications like chatbots, document Q&A, and AI workflow.\n",
      "\n",
      "2Ô∏è‚É£ Follow-up\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: LangChainRetriever\n",
      "Action Input: creator\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain was created by Harrison Chase.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: LangChain was created by Harrison Chase.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: LangChain was created by Harrison Chase.\n",
      "\n",
      "3Ô∏è‚É£ Combined Reasoning\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: LangChainRetriever\n",
      "Action Input: LangChain's use in AI workflows\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain is commonly used in AI workflows for tasks such as chatbots, document question and answering (Q&A), and other applications that involve natural language processing. It provides support for various components like RAG, agents, memory, and tools, making it a versatile framework for building applications with large language models (LLMs).\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: LangChain is commonly used in AI workflows for tasks such as chatbots, document question and answering (Q&A), and other applications that involve natural language processing. It provides support for various components like RAG, agents, memory, and tools, making it a versatile framework for building applications with large language models (LLMs).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: LangChain is commonly used in AI workflows for tasks such as chatbots, document question and answering (Q&A), and other applications that involve natural language processing. It provides support for various components like RAG, agents, memory, and tools, making it a versatile framework for building applications with large language models (LLMs).\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Install if not already done\n",
    "# !pip install langchain openai faiss-cpu tiktoken python-dotenv\n",
    "\n",
    "# 1Ô∏è‚É£ Imports\n",
    "from langchain.agents import Tool, AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 2Ô∏è‚É£ Load API keys\n",
    "load_dotenv(\".env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 3Ô∏è‚É£ Setup LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 4Ô∏è‚É£ Create Vector DB (Retriever)\n",
    "\n",
    "with open(\"sample.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "# üß† Split the text into smaller chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=300, chunk_overlap=50)\n",
    "texts = splitter.split_text(text_data)\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 5Ô∏è‚É£ Create RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# 6Ô∏è‚É£ Convert to LangChain Tool\n",
    "qa_tool = Tool(\n",
    "    name=\"LangChainRetriever\",\n",
    "    func=qa_chain.run,\n",
    "    description=\"Use this to answer questions about LangChain framework, features, or its creator.\"\n",
    ")\n",
    "\n",
    "# 7Ô∏è‚É£ Setup Memory (to support conversational context)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 8Ô∏è‚É£ Initialize Agent with Tool + Memory\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,  # ReAct agent\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# 9Ô∏è‚É£ Ask Questions (RAG-Style)\n",
    "print(\"1Ô∏è‚É£ First Question\")\n",
    "res1 = agent.run(\"What is LangChain?\")\n",
    "print(\"Answer:\", res1)\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Follow-up\")\n",
    "res2 = agent.run(\"Who created it?\")\n",
    "print(\"Answer:\", res2)\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Combined Reasoning\")\n",
    "res3 = agent.run(\"Explain LangChain's use in AI workflows.\")\n",
    "print(\"Answer:\", res3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dda771-5dff-4030-a646-ee2107bff33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
